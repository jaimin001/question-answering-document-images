{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jaiminsg/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/jaiminsg/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'BertLayerNorm' from 'transformers.models.bert.modeling_bert' (/Users/jaiminsg/Library/Python/3.9/lib/python/site-packages/transformers/models/bert/modeling_bert.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodeling_layoutlm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LayoutLMForTokenClassification\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      4\u001b[0m     BertConfig,\n\u001b[1;32m      5\u001b[0m     BertTokenizer,\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils_docvqa\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      8\u001b[0m     read_docvqa_examples,\n\u001b[1;32m      9\u001b[0m     convert_examples_to_features)\n",
      "File \u001b[0;32m/Volumes/T7/new btp/BTP/docvqa/modeling_layoutlm.py:11\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BertPreTrainedModel\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# from transformers.modeling_bert import (\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#     BertEncoder,\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#     BertPooler,\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#     BertLayerNorm,\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbert\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_bert\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     12\u001b[0m     BertEncoder,\n\u001b[1;32m     13\u001b[0m     BertPooler,\n\u001b[1;32m     14\u001b[0m     BertLayerNorm,\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mLayoutLMEmbeddings\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m     19\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Construct the embeddings from word, position and token_type embeddings.\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'BertLayerNorm' from 'transformers.models.bert.modeling_bert' (/Users/jaiminsg/Library/Python/3.9/lib/python/site-packages/transformers/models/bert/modeling_bert.py)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from modeling_layoutlm import LayoutLMForTokenClassification\n",
    "from transformers import (\n",
    "    BertConfig,\n",
    "    BertTokenizer,\n",
    ")\n",
    "from utils_docvqa import (\n",
    "    read_docvqa_examples,\n",
    "    convert_examples_to_features)\n",
    "from torch.utils.data import DataLoader, SequentialSampler, TensorDataset\n",
    "from transformers.data.processors.squad import SquadResult\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_FOLDER = \"./models/\"\n",
    "SAMPLE_DATA = \"./models/sample_data.json\"\n",
    "LABELS = [\"start\",\"end\"]\n",
    "pad_token_label_id=-100\n",
    "labels = [\"start\",\"end\"]\n",
    "max_seq_length = 512\n",
    "max_query_length = 64\n",
    "doc_stride = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "torch.cuda.set_device(device)\n",
    "model_class = LayoutLMForTokenClassification\n",
    "config_class = BertConfig\n",
    "tokenizer_class = BertTokenizer\n",
    "config = config_class.from_pretrained(MODEL_FOLDER,num_labels=2,cache_dir=None)\n",
    "model = model_class.from_pretrained(MODEL_FOLDER)\n",
    "tokenizer = tokenizer_class.from_pretrained(MODEL_FOLDER,do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /mnt/anisha/code/docvqa/utils_docvqa.py:95: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "examples = read_docvqa_examples(SAMPLE_DATA, is_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = convert_examples_to_features(\n",
    "            examples=examples,\n",
    "            label_list=labels,\n",
    "            tokenizer=tokenizer,\n",
    "            max_seq_length=max_seq_length,\n",
    "            doc_stride=doc_stride,\n",
    "            max_query_length=max_query_length,\n",
    "            is_training=False,\n",
    "            pad_token_label_id=pad_token_label_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n",
    "all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n",
    "all_bboxes = torch.tensor([f.boxes for f in features], dtype=torch.long)\n",
    "all_example_index = torch.arange(all_input_ids.size(0), dtype=torch.long)\n",
    "\n",
    "eval_dataset = TensorDataset(\n",
    "        all_input_ids, all_input_mask, all_segment_ids,all_bboxes,all_example_index)\n",
    "eval_batch_size = 1\n",
    "eval_sampler = (\n",
    "        SequentialSampler(eval_dataset))\n",
    "\n",
    "eval_dataloader = DataLoader(\n",
    "        eval_dataset, sampler=eval_sampler, batch_size=eval_batch_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 32.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is the contact person name mentioned in letter ?\n",
      "maura payne\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "all_results = []\n",
    "\n",
    "def to_list(tensor):\n",
    "    return tensor.detach().cpu().tolist()\n",
    "\n",
    "for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "    model.eval()\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    with torch.no_grad():\n",
    "        inputs = {\n",
    "            \"input_ids\": batch[0],\n",
    "            \"attention_mask\": batch[1],\n",
    "        }\n",
    "        inputs[\"bbox\"] = batch[3]\n",
    "        inputs[\"token_type_ids\"] = (batch[2])\n",
    "        outputs = model(**inputs)\n",
    "    example_indices = batch[4]\n",
    "\n",
    "    for i, example_index in enumerate(example_indices):\n",
    "        eval_feature = features[example_index.item()]\n",
    "        unique_id = int(eval_feature.unique_id)\n",
    "\n",
    "        output = [to_list(output[i]) for output in outputs]\n",
    "\n",
    "        start_logits, end_logits = output\n",
    "        result = SquadResult(unique_id, start_logits, end_logits)\n",
    "        all_results.append(result)\n",
    "predictions_json = {}\n",
    "assert len(all_results)==len(features)\n",
    "for i in range(len(all_results)):\n",
    "    start_index = np.argmax(all_results[i].start_logits)\n",
    "    end_index = np.argmax(all_results[i].end_logits)\n",
    "    pred_answer = features[i].tokens[start_index:end_index+1]\n",
    "    pred_answer = ' '.join([x for x in pred_answer])\n",
    "    pred_text = pred_answer.replace(' ##', '')\n",
    "    question = features[i].tokens[1:features[i].tokens.index('[SEP]')]\n",
    "    question_text = ' '.join([x for x in question])\n",
    "    question_text = question_text.replace(' ##', '')\n",
    "    print(question_text)\n",
    "    print(pred_text)\n",
    "   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

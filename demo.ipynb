{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hari/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from modeling_layoutlm import LayoutLMForTokenClassification\n",
    "from transformers import (\n",
    "    BertConfig,\n",
    "    BertTokenizer,\n",
    ")\n",
    "from utils_docvqa import (\n",
    "    read_docvqa_examples,\n",
    "    convert_examples_to_features)\n",
    "from torch.utils.data import DataLoader, SequentialSampler, TensorDataset\n",
    "from transformers.data.processors.squad import SquadResult\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bounding_box import save_bounding_boxes\n",
    "SAMPLE_DATA = save_bounding_boxes(\n",
    "    image_path=\"fsgj0223_84.png\",\n",
    "    questions=[\n",
    "        \"What is the title of the document?\",\n",
    "        \"What is the numerical interest?\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_FOLDER = \"./models/\"\n",
    "LABELS = [\"start\",\"end\"]\n",
    "pad_token_label_id=-100\n",
    "labels = [\"start\",\"end\"]\n",
    "max_seq_length = 512\n",
    "max_query_length = 64\n",
    "doc_stride = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda:0\")\n",
    "device = torch.device(\"cpu\")\n",
    "# torch.cuda.set_device(device)\n",
    "model_class = LayoutLMForTokenClassification\n",
    "config_class = BertConfig\n",
    "tokenizer_class = BertTokenizer\n",
    "config = config_class.from_pretrained(MODEL_FOLDER,num_labels=2,cache_dir=None)\n",
    "model = model_class.from_pretrained(MODEL_FOLDER)\n",
    "tokenizer = tokenizer_class.from_pretrained(MODEL_FOLDER,do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = read_docvqa_examples(SAMPLE_DATA, is_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000000\n",
      "INFO:tensorflow:example_index: 0\n",
      "INFO:tensorflow:doc_span_index: 0\n",
      "INFO:tensorflow:tokens: [CLS] what is the title of the document ? [SEP] @ tt . management report of the directors an discussion & analysis your directors here ##by submit their forty eighth annual report with the audit ##ed accounts for the year ended 31 \" march , 2004 . summary of financial result : for the year for the year ended ended 31 . 03 . 2004 31 . 03 . 2003 ( rs . in lac ##s ) profit for the year before interest , de ##pre ##ciation and exceptional items : 296 ##1 . 59 269 ##7 . 42 interest 41 ##45 / 90 104 ##7 - 79 de ##pre ##ciation 240 . 76 281 . 73 profit bo ##for ##e tax and exceptional items 1874 . 93 136 ##7 . 90 exceptional te ##ms ( 289 . 65 ) ( 48 ##4 . 68 ) de ##pre ##ciation of eat ##lier yo ##ars — ( 145 . 94 ) prof ##il before taxation 128 ##5 . 28 76 ##7 . 28 provision for taxation current tax ( wealth tax ) 5 . 75 5 . 09 deter ##red tax 53 ##1 - 81 286 . 97 profit after taxation 747 . 72 475 . 22 amount transferred from de ##ben ##ture redemption reserve — 350 . 00 balance brought forward from last year ( 309 ##8 . 08 ) ( 139 ##23 . 30 ) balance of loss carried over to balance sheet ( 123 ##50 . 36 ) ( 130 ##9 ##8 . 08 ) industry structure and development : the industry posted a 3 % growth in volumes over the pr ##avio ##us year . however , your company ' s volumes grew by 7 % compared to last year . further , in the economy non - filtered segment , where your company mainly operates , with thrust in the rural market , our market share has increased to 36 % for the financial year 2003 - 04 compared to 31 % last year . ins ##pit ##e of challenges faced by the industry in terms of high state level taxes in form of luxury and / or entry tax ; smug ##gled cigarettes finding their way into the domestic market and with the implementation of the ‘ cigarettes and other tobacco products ( prohibition of advertisement & regulation of trade & commerce , production , supply & distribution ) act , 2003 ' effective from 1 * may , 2004 , your company is st ##ri ##ving to increase its sales volumes and market share , especially in its core markets . rehabilitation package : the rehabilitation package as approved by the board for industrial and financial reconstruction ( bi ##fr ) vi ##de its order dated 16 / 12 / 2002 is being implemented sat ##ista ##ctor ##ily . the management committee is monitoring the progress of the scheme . financial performance with respect to operational performance ‘ the sales revenue of your company during the year was at rs . 307 ##46 . 16 [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 10:4 11:4 12:4 13:8 14:28 15:29 16:30 17:31 18:32 19:34 20:35 21:36 22:40 23:41 24:42 25:42 26:43 27:44 28:45 29:46 30:47 31:48 32:49 33:50 34:51 35:51 36:52 37:53 38:54 39:55 40:56 41:57 42:57 43:58 44:58 45:59 46:59 47:67 48:68 49:69 50:70 51:70 52:78 53:79 54:80 55:81 56:82 57:83 58:85 59:86 60:88 61:88 62:88 63:88 64:88 65:89 66:89 67:89 68:89 69:89 70:93 71:93 72:93 73:94 74:95 75:95 76:95 77:99 78:100 79:101 80:102 81:103 82:104 83:104 84:108 85:108 86:108 87:109 88:110 89:111 90:111 91:112 92:112 93:112 94:112 95:113 96:113 97:113 98:113 99:115 100:116 101:116 102:116 103:116 104:117 105:117 106:117 107:117 108:119 109:119 110:119 111:120 112:120 113:120 114:121 115:121 116:121 117:123 118:124 119:124 120:124 121:125 122:126 123:127 124:128 125:129 126:129 127:129 128:130 129:130 130:130 131:130 132:132 133:133 134:133 135:134 136:134 137:134 138:134 139:134 140:135 141:135 142:135 143:135 144:135 145:135 146:137 147:137 148:137 149:138 150:139 151:139 152:140 153:140 154:141 155:142 156:142 157:142 158:142 159:142 160:144 161:144 162:145 163:146 164:147 165:147 166:147 167:147 168:148 169:148 170:148 171:148 172:150 173:151 174:152 175:155 176:156 177:157 178:157 179:158 180:158 181:159 182:159 183:159 184:160 185:160 186:160 187:162 188:162 189:163 190:164 191:164 192:164 193:164 194:165 195:165 196:165 197:167 198:168 199:169 200:170 201:170 202:170 203:171 204:171 205:171 206:173 207:174 208:175 209:176 210:176 211:176 212:177 213:178 214:179 215:180 216:180 217:180 218:182 219:183 220:184 221:185 222:186 223:187 224:188 225:188 226:188 227:188 228:188 229:188 230:189 231:189 232:189 233:189 234:189 235:189 236:191 237:192 238:193 239:194 240:195 241:196 242:197 243:198 244:199 245:199 246:199 247:199 248:199 249:199 250:200 251:200 252:200 253:200 254:200 255:200 256:200 257:208 258:209 259:210 260:211 261:211 262:215 263:216 264:217 265:218 266:219 267:219 268:220 269:221 270:222 271:223 272:224 273:225 274:225 275:225 276:226 277:226 278:227 279:227 280:228 281:229 282:229 283:229 284:230 285:231 286:232 287:233 288:233 289:234 290:235 291:237 292:238 293:238 294:239 295:239 296:240 297:241 298:242 299:243 300:243 301:243 302:244 303:244 304:245 305:246 306:247 307:248 308:249 309:249 310:250 311:251 312:252 313:253 314:254 315:255 316:255 317:256 318:258 319:259 320:260 321:261 322:262 323:263 324:263 325:264 326:265 327:266 328:267 329:268 330:268 331:268 332:269 333:270 334:271 335:271 336:272 337:273 338:273 339:277 340:277 341:277 342:278 343:279 344:280 345:281 346:282 347:283 348:284 349:285 350:286 351:287 352:288 353:289 354:290 355:291 356:292 357:293 358:294 359:295 360:295 361:296 362:297 363:298 364:298 365:299 366:299 367:301 368:302 369:303 370:304 371:305 372:306 373:307 374:308 375:309 376:310 377:311 378:312 379:313 380:314 381:315 382:315 383:316 384:317 385:318 386:319 387:321 388:321 389:322 390:323 391:324 392:325 393:326 394:327 395:328 396:329 397:329 398:330 399:330 400:331 401:332 402:333 403:333 404:334 405:334 406:335 407:335 408:336 409:337 410:339 411:339 412:340 413:340 414:341 415:341 416:342 417:343 418:344 419:345 420:345 421:345 422:346 423:347 424:348 425:349 426:350 427:351 428:352 429:353 430:353 431:354 432:355 433:356 434:357 435:358 436:358 437:362 438:363 439:363 440:367 441:368 442:369 443:370 444:371 445:372 446:373 447:374 448:375 449:376 450:377 451:378 452:379 453:380 454:380 455:380 456:380 457:381 458:381 459:382 460:383 461:384 462:386 463:386 464:386 465:386 466:386 467:387 468:388 469:389 470:390 471:390 472:390 473:390 474:390 475:391 476:392 477:393 478:394 479:395 480:396 481:397 482:398 483:399 484:400 485:400 486:404 487:405 488:406 489:407 490:408 491:409 492:410 493:414 494:414 495:415 496:416 497:417 498:418 499:419 500:420 501:421 502:422 503:423 504:424 505:425 506:425 507:426 508:426 509:426 510:426\n",
      "INFO:tensorflow:token_is_max_context: 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False 383:False 384:False 385:False 386:False 387:False 388:False 389:False 390:False 391:False 392:False 393:False 394:False 395:False 396:False 397:False 398:False 399:False 400:False 401:False 402:False 403:False 404:False 405:False 406:False 407:False 408:False 409:False 410:False 411:False 412:False 413:False 414:False 415:False 416:False 417:False 418:False 419:False 420:False 421:False 422:False 423:False 424:False 425:False 426:False 427:False 428:False 429:False 430:False 431:False 432:False 433:False 434:False 435:False 436:False 437:False 438:False 439:False 440:False 441:False 442:False 443:False 444:False 445:False 446:False 447:False 448:False 449:False 450:False 451:False 452:False 453:False 454:False 455:False 456:False 457:False 458:False 459:False 460:False 461:False 462:False 463:False 464:False 465:False 466:False 467:False 468:False 469:False 470:False 471:False 472:False 473:False 474:False 475:False 476:False 477:False 478:False 479:False 480:False 481:False 482:False 483:False 484:False 485:False 486:False 487:False 488:False 489:False 490:False 491:False 492:False 493:False 494:False 495:False 496:False 497:False 498:False 499:False 500:False 501:False 502:False 503:False 504:False 505:False 506:False 507:False 508:False 509:False 510:False\n",
      "INFO:tensorflow:input_ids: 101 2054 2003 1996 2516 1997 1996 6254 1029 102 1030 23746 1012 2968 3189 1997 1996 5501 2019 6594 1004 4106 2115 5501 2182 3762 12040 2037 5659 5964 3296 3189 2007 1996 15727 2098 6115 2005 1996 2095 3092 2861 1000 2233 1010 2432 1012 12654 1997 3361 2765 1024 2005 1996 2095 2005 1996 2095 3092 3092 2861 1012 6021 1012 2432 2861 1012 6021 1012 2494 1006 12667 1012 1999 18749 2015 1007 5618 2005 1996 2095 2077 3037 1010 2139 28139 23247 1998 11813 5167 1024 27200 2487 1012 5354 25717 2581 1012 4413 3037 4601 19961 1013 3938 9645 2581 1011 6535 2139 28139 23247 11212 1012 6146 22955 1012 6421 5618 8945 29278 2063 4171 1998 11813 5167 7586 1012 6109 15407 2581 1012 3938 11813 8915 5244 1006 27054 1012 3515 1007 1006 4466 2549 1012 6273 1007 2139 28139 23247 1997 4521 14355 10930 11650 1517 1006 13741 1012 6365 1007 11268 4014 2077 14952 11899 2629 1012 2654 6146 2581 1012 2654 9347 2005 14952 2783 4171 1006 7177 4171 1007 1019 1012 4293 1019 1012 5641 28283 5596 4171 5187 2487 1011 6282 24921 1012 5989 5618 2044 14952 25374 1012 5824 28245 1012 2570 3815 4015 2013 2139 10609 11244 18434 3914 1517 8698 1012 4002 5703 2716 2830 2013 2197 2095 1006 25048 2620 1012 5511 1007 1006 16621 21926 1012 2382 1007 5703 1997 3279 3344 2058 2000 5703 7123 1006 13138 12376 1012 4029 1007 1006 7558 2683 2620 1012 5511 1007 3068 3252 1998 2458 1024 1996 3068 6866 1037 1017 1003 3930 1999 6702 2058 1996 10975 28471 2271 2095 1012 2174 1010 2115 2194 1005 1055 6702 3473 2011 1021 1003 4102 2000 2197 2095 1012 2582 1010 1999 1996 4610 2512 1011 21839 6903 1010 2073 2115 2194 3701 5748 1010 2007 7400 1999 1996 3541 3006 1010 2256 3006 3745 2038 3445 2000 4029 1003 2005 1996 3361 2095 2494 1011 5840 4102 2000 2861 1003 2197 2095 1012 16021 23270 2063 1997 7860 4320 2011 1996 3068 1999 3408 1997 2152 2110 2504 7773 1999 2433 1997 9542 1998 1013 2030 4443 4171 1025 20673 11533 15001 4531 2037 2126 2046 1996 4968 3006 1998 2007 1996 7375 1997 1996 1520 15001 1998 2060 9098 3688 1006 13574 1997 15147 1004 7816 1997 3119 1004 6236 1010 2537 1010 4425 1004 4353 1007 2552 1010 2494 1005 4621 2013 1015 1008 2089 1010 2432 1010 2115 2194 2003 2358 3089 6455 2000 3623 2049 4341 6702 1998 3006 3745 1010 2926 1999 2049 4563 6089 1012 11252 7427 1024 1996 11252 7427 2004 4844 2011 1996 2604 2005 3919 1998 3361 8735 1006 12170 19699 1007 6819 3207 2049 2344 6052 2385 1013 2260 1013 2526 2003 2108 7528 2938 11921 16761 6588 1012 1996 2968 2837 2003 8822 1996 5082 1997 1996 5679 1012 3361 2836 2007 4847 2000 6515 2836 1520 1996 4341 6599 1997 2115 2194 2076 1996 2095 2001 2012 12667 1012 24559 21472 1012 2385 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000001\n",
      "INFO:tensorflow:example_index: 0\n",
      "INFO:tensorflow:doc_span_index: 1\n",
      "INFO:tensorflow:tokens: [CLS] what is the title of the document ? [SEP] 65 ) ( 48 ##4 . 68 ) de ##pre ##ciation of eat ##lier yo ##ars — ( 145 . 94 ) prof ##il before taxation 128 ##5 . 28 76 ##7 . 28 provision for taxation current tax ( wealth tax ) 5 . 75 5 . 09 deter ##red tax 53 ##1 - 81 286 . 97 profit after taxation 747 . 72 475 . 22 amount transferred from de ##ben ##ture redemption reserve — 350 . 00 balance brought forward from last year ( 309 ##8 . 08 ) ( 139 ##23 . 30 ) balance of loss carried over to balance sheet ( 123 ##50 . 36 ) ( 130 ##9 ##8 . 08 ) industry structure and development : the industry posted a 3 % growth in volumes over the pr ##avio ##us year . however , your company ' s volumes grew by 7 % compared to last year . further , in the economy non - filtered segment , where your company mainly operates , with thrust in the rural market , our market share has increased to 36 % for the financial year 2003 - 04 compared to 31 % last year . ins ##pit ##e of challenges faced by the industry in terms of high state level taxes in form of luxury and / or entry tax ; smug ##gled cigarettes finding their way into the domestic market and with the implementation of the ‘ cigarettes and other tobacco products ( prohibition of advertisement & regulation of trade & commerce , production , supply & distribution ) act , 2003 ' effective from 1 * may , 2004 , your company is st ##ri ##ving to increase its sales volumes and market share , especially in its core markets . rehabilitation package : the rehabilitation package as approved by the board for industrial and financial reconstruction ( bi ##fr ) vi ##de its order dated 16 / 12 / 2002 is being implemented sat ##ista ##ctor ##ily . the management committee is monitoring the progress of the scheme . financial performance with respect to operational performance ‘ the sales revenue of your company during the year was at rs . 307 ##46 . 16 lac ##s as against as . $ 284 ##0 . 94 lac ##s in the previous year , showing a decline of 6 . 38 % , however , the profit after tax for the year increased by around 57 % from fis , 475 . 22 lac ##s in the previous year to his . 747 . 72 lac ##s this year . the export revenue generated during the year 2003 - 04 was fis . 243 ##0 . 03 lac ##s . this performance has been fuel ##led inter ali ##a , by various planned new marketing initiatives bearing fruit , which has expanded ‘ our consumer base apart from the se ##vera ##i cost saving measures undertaken by your company in its operations , your [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 10:134 11:134 12:135 13:135 14:135 15:135 16:135 17:135 18:137 19:137 20:137 21:138 22:139 23:139 24:140 25:140 26:141 27:142 28:142 29:142 30:142 31:142 32:144 33:144 34:145 35:146 36:147 37:147 38:147 39:147 40:148 41:148 42:148 43:148 44:150 45:151 46:152 47:155 48:156 49:157 50:157 51:158 52:158 53:159 54:159 55:159 56:160 57:160 58:160 59:162 60:162 61:163 62:164 63:164 64:164 65:164 66:165 67:165 68:165 69:167 70:168 71:169 72:170 73:170 74:170 75:171 76:171 77:171 78:173 79:174 80:175 81:176 82:176 83:176 84:177 85:178 86:179 87:180 88:180 89:180 90:182 91:183 92:184 93:185 94:186 95:187 96:188 97:188 98:188 99:188 100:188 101:188 102:189 103:189 104:189 105:189 106:189 107:189 108:191 109:192 110:193 111:194 112:195 113:196 114:197 115:198 116:199 117:199 118:199 119:199 120:199 121:199 122:200 123:200 124:200 125:200 126:200 127:200 128:200 129:208 130:209 131:210 132:211 133:211 134:215 135:216 136:217 137:218 138:219 139:219 140:220 141:221 142:222 143:223 144:224 145:225 146:225 147:225 148:226 149:226 150:227 151:227 152:228 153:229 154:229 155:229 156:230 157:231 158:232 159:233 160:233 161:234 162:235 163:237 164:238 165:238 166:239 167:239 168:240 169:241 170:242 171:243 172:243 173:243 174:244 175:244 176:245 177:246 178:247 179:248 180:249 181:249 182:250 183:251 184:252 185:253 186:254 187:255 188:255 189:256 190:258 191:259 192:260 193:261 194:262 195:263 196:263 197:264 198:265 199:266 200:267 201:268 202:268 203:268 204:269 205:270 206:271 207:271 208:272 209:273 210:273 211:277 212:277 213:277 214:278 215:279 216:280 217:281 218:282 219:283 220:284 221:285 222:286 223:287 224:288 225:289 226:290 227:291 228:292 229:293 230:294 231:295 232:295 233:296 234:297 235:298 236:298 237:299 238:299 239:301 240:302 241:303 242:304 243:305 244:306 245:307 246:308 247:309 248:310 249:311 250:312 251:313 252:314 253:315 254:315 255:316 256:317 257:318 258:319 259:321 260:321 261:322 262:323 263:324 264:325 265:326 266:327 267:328 268:329 269:329 270:330 271:330 272:331 273:332 274:333 275:333 276:334 277:334 278:335 279:335 280:336 281:337 282:339 283:339 284:340 285:340 286:341 287:341 288:342 289:343 290:344 291:345 292:345 293:345 294:346 295:347 296:348 297:349 298:350 299:351 300:352 301:353 302:353 303:354 304:355 305:356 306:357 307:358 308:358 309:362 310:363 311:363 312:367 313:368 314:369 315:370 316:371 317:372 318:373 319:374 320:375 321:376 322:377 323:378 324:379 325:380 326:380 327:380 328:380 329:381 330:381 331:382 332:383 333:384 334:386 335:386 336:386 337:386 338:386 339:387 340:388 341:389 342:390 343:390 344:390 345:390 346:390 347:391 348:392 349:393 350:394 351:395 352:396 353:397 354:398 355:399 356:400 357:400 358:404 359:405 360:406 361:407 362:408 363:409 364:410 365:414 366:414 367:415 368:416 369:417 370:418 371:419 372:420 373:421 374:422 375:423 376:424 377:425 378:425 379:426 380:426 381:426 382:426 383:427 384:427 385:428 386:429 387:430 388:430 389:431 390:431 391:431 392:431 393:431 394:432 395:432 396:433 397:434 398:435 399:437 400:437 401:438 402:439 403:440 404:441 405:442 406:442 407:442 408:442 409:442 410:443 411:443 412:444 413:445 414:446 415:447 416:448 417:449 418:450 419:451 420:452 421:453 422:454 423:454 424:455 425:456 426:456 427:457 428:457 429:457 430:458 431:458 432:459 433:460 434:462 435:463 436:464 437:465 438:465 439:465 440:465 441:465 442:466 443:466 444:467 445:468 446:468 447:469 448:470 449:471 450:472 451:473 452:474 453:475 454:476 455:476 456:476 457:477 458:478 459:478 460:479 461:479 462:479 463:479 464:480 465:480 466:480 467:484 468:485 469:486 470:487 471:488 472:488 473:489 474:490 475:490 476:490 477:491 478:492 479:493 480:494 481:495 482:496 483:497 484:498 485:498 486:499 487:500 488:501 489:503 490:503 491:504 492:505 493:506 494:507 495:508 496:509 497:509 498:509 499:510 500:511 501:512 502:513 503:514 504:515 505:516 506:517 507:518 508:519 509:519 510:520\n",
      "INFO:tensorflow:token_is_max_context: 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:False 134:False 135:False 136:False 137:False 138:False 139:False 140:False 141:False 142:False 143:False 144:False 145:False 146:False 147:False 148:False 149:False 150:False 151:False 152:False 153:False 154:False 155:False 156:False 157:False 158:False 159:False 160:False 161:False 162:False 163:False 164:False 165:False 166:False 167:False 168:False 169:False 170:False 171:False 172:False 173:False 174:False 175:False 176:False 177:False 178:False 179:False 180:False 181:False 182:False 183:False 184:False 185:False 186:False 187:False 188:False 189:False 190:False 191:False 192:False 193:False 194:False 195:False 196:False 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False 383:False 384:False 385:False 386:False 387:False 388:False 389:False 390:False 391:False 392:False 393:False 394:False 395:False 396:False 397:False 398:False 399:False 400:False 401:False 402:False 403:False 404:False 405:False 406:False 407:False 408:False 409:False 410:False 411:False 412:False 413:False 414:False 415:False 416:False 417:False 418:False 419:False 420:False 421:False 422:False 423:False 424:False 425:False 426:False 427:False 428:False 429:False 430:False 431:False 432:False 433:False 434:False 435:False 436:False 437:False 438:False 439:False 440:False 441:False 442:False 443:False 444:False 445:False 446:False 447:False 448:False 449:False 450:False 451:False 452:False 453:False 454:False 455:False 456:False 457:False 458:False 459:False 460:False 461:False 462:False 463:False 464:False 465:False 466:False 467:False 468:False 469:False 470:False 471:False 472:False 473:False 474:False 475:False 476:False 477:False 478:False 479:False 480:False 481:False 482:False 483:False 484:False 485:False 486:False 487:False 488:False 489:False 490:False 491:False 492:False 493:False 494:False 495:False 496:False 497:False 498:False 499:False 500:False 501:False 502:False 503:False 504:False 505:False 506:False 507:False 508:False 509:False 510:False\n",
      "INFO:tensorflow:input_ids: 101 2054 2003 1996 2516 1997 1996 6254 1029 102 3515 1007 1006 4466 2549 1012 6273 1007 2139 28139 23247 1997 4521 14355 10930 11650 1517 1006 13741 1012 6365 1007 11268 4014 2077 14952 11899 2629 1012 2654 6146 2581 1012 2654 9347 2005 14952 2783 4171 1006 7177 4171 1007 1019 1012 4293 1019 1012 5641 28283 5596 4171 5187 2487 1011 6282 24921 1012 5989 5618 2044 14952 25374 1012 5824 28245 1012 2570 3815 4015 2013 2139 10609 11244 18434 3914 1517 8698 1012 4002 5703 2716 2830 2013 2197 2095 1006 25048 2620 1012 5511 1007 1006 16621 21926 1012 2382 1007 5703 1997 3279 3344 2058 2000 5703 7123 1006 13138 12376 1012 4029 1007 1006 7558 2683 2620 1012 5511 1007 3068 3252 1998 2458 1024 1996 3068 6866 1037 1017 1003 3930 1999 6702 2058 1996 10975 28471 2271 2095 1012 2174 1010 2115 2194 1005 1055 6702 3473 2011 1021 1003 4102 2000 2197 2095 1012 2582 1010 1999 1996 4610 2512 1011 21839 6903 1010 2073 2115 2194 3701 5748 1010 2007 7400 1999 1996 3541 3006 1010 2256 3006 3745 2038 3445 2000 4029 1003 2005 1996 3361 2095 2494 1011 5840 4102 2000 2861 1003 2197 2095 1012 16021 23270 2063 1997 7860 4320 2011 1996 3068 1999 3408 1997 2152 2110 2504 7773 1999 2433 1997 9542 1998 1013 2030 4443 4171 1025 20673 11533 15001 4531 2037 2126 2046 1996 4968 3006 1998 2007 1996 7375 1997 1996 1520 15001 1998 2060 9098 3688 1006 13574 1997 15147 1004 7816 1997 3119 1004 6236 1010 2537 1010 4425 1004 4353 1007 2552 1010 2494 1005 4621 2013 1015 1008 2089 1010 2432 1010 2115 2194 2003 2358 3089 6455 2000 3623 2049 4341 6702 1998 3006 3745 1010 2926 1999 2049 4563 6089 1012 11252 7427 1024 1996 11252 7427 2004 4844 2011 1996 2604 2005 3919 1998 3361 8735 1006 12170 19699 1007 6819 3207 2049 2344 6052 2385 1013 2260 1013 2526 2003 2108 7528 2938 11921 16761 6588 1012 1996 2968 2837 2003 8822 1996 5082 1997 1996 5679 1012 3361 2836 2007 4847 2000 6515 2836 1520 1996 4341 6599 1997 2115 2194 2076 1996 2095 2001 2012 12667 1012 24559 21472 1012 2385 18749 2015 2004 2114 2004 1012 1002 26871 2692 1012 6365 18749 2015 1999 1996 3025 2095 1010 4760 1037 6689 1997 1020 1012 4229 1003 1010 2174 1010 1996 5618 2044 4171 2005 1996 2095 3445 2011 2105 5401 1003 2013 27424 1010 28245 1012 2570 18749 2015 1999 1996 3025 2095 2000 2010 1012 25374 1012 5824 18749 2015 2023 2095 1012 1996 9167 6599 7013 2076 1996 2095 2494 1011 5840 2001 27424 1012 22884 2692 1012 6021 18749 2015 1012 2023 2836 2038 2042 4762 3709 6970 4862 2050 1010 2011 2536 3740 2047 5821 11107 7682 5909 1010 2029 2038 4423 1520 2256 7325 2918 4237 2013 1996 7367 26061 2072 3465 7494 5761 10607 2011 2115 2194 1999 2049 3136 1010 2115 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000002\n",
      "INFO:tensorflow:example_index: 0\n",
      "INFO:tensorflow:doc_span_index: 2\n",
      "INFO:tensorflow:tokens: [CLS] what is the title of the document ? [SEP] 3 % growth in volumes over the pr ##avio ##us year . however , your company ' s volumes grew by 7 % compared to last year . further , in the economy non - filtered segment , where your company mainly operates , with thrust in the rural market , our market share has increased to 36 % for the financial year 2003 - 04 compared to 31 % last year . ins ##pit ##e of challenges faced by the industry in terms of high state level taxes in form of luxury and / or entry tax ; smug ##gled cigarettes finding their way into the domestic market and with the implementation of the ‘ cigarettes and other tobacco products ( prohibition of advertisement & regulation of trade & commerce , production , supply & distribution ) act , 2003 ' effective from 1 * may , 2004 , your company is st ##ri ##ving to increase its sales volumes and market share , especially in its core markets . rehabilitation package : the rehabilitation package as approved by the board for industrial and financial reconstruction ( bi ##fr ) vi ##de its order dated 16 / 12 / 2002 is being implemented sat ##ista ##ctor ##ily . the management committee is monitoring the progress of the scheme . financial performance with respect to operational performance ‘ the sales revenue of your company during the year was at rs . 307 ##46 . 16 lac ##s as against as . $ 284 ##0 . 94 lac ##s in the previous year , showing a decline of 6 . 38 % , however , the profit after tax for the year increased by around 57 % from fis , 475 . 22 lac ##s in the previous year to his . 747 . 72 lac ##s this year . the export revenue generated during the year 2003 - 04 was fis . 243 ##0 . 03 lac ##s . this performance has been fuel ##led inter ali ##a , by various planned new marketing initiatives bearing fruit , which has expanded ‘ our consumer base apart from the se ##vera ##i cost saving measures undertaken by your company in its operations , your company continues to have the single largest brand in the mini cigarettes segment in the country , steadily adding to its market share . in view of the accumulated losses , your directors are unable to recommend a divide ##nd . fixed deposit : there are no fixed deposit due ##s pending repay ##ment by the company . interest free contributions have been received from associates towards ‘ promoters ’ contribution ’ , as directed by the bi ##fr vi ##de its order dated 16 \" december , 2002 app ##roving the rehabilitation scheme . the company has applied to the department of company affairs for exempt ##ing these receipts from provisions of section s ##8 ##a of the companies act , 1956 and other applicable rules and [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 10:219 11:219 12:220 13:221 14:222 15:223 16:224 17:225 18:225 19:225 20:226 21:226 22:227 23:227 24:228 25:229 26:229 27:229 28:230 29:231 30:232 31:233 32:233 33:234 34:235 35:237 36:238 37:238 38:239 39:239 40:240 41:241 42:242 43:243 44:243 45:243 46:244 47:244 48:245 49:246 50:247 51:248 52:249 53:249 54:250 55:251 56:252 57:253 58:254 59:255 60:255 61:256 62:258 63:259 64:260 65:261 66:262 67:263 68:263 69:264 70:265 71:266 72:267 73:268 74:268 75:268 76:269 77:270 78:271 79:271 80:272 81:273 82:273 83:277 84:277 85:277 86:278 87:279 88:280 89:281 90:282 91:283 92:284 93:285 94:286 95:287 96:288 97:289 98:290 99:291 100:292 101:293 102:294 103:295 104:295 105:296 106:297 107:298 108:298 109:299 110:299 111:301 112:302 113:303 114:304 115:305 116:306 117:307 118:308 119:309 120:310 121:311 122:312 123:313 124:314 125:315 126:315 127:316 128:317 129:318 130:319 131:321 132:321 133:322 134:323 135:324 136:325 137:326 138:327 139:328 140:329 141:329 142:330 143:330 144:331 145:332 146:333 147:333 148:334 149:334 150:335 151:335 152:336 153:337 154:339 155:339 156:340 157:340 158:341 159:341 160:342 161:343 162:344 163:345 164:345 165:345 166:346 167:347 168:348 169:349 170:350 171:351 172:352 173:353 174:353 175:354 176:355 177:356 178:357 179:358 180:358 181:362 182:363 183:363 184:367 185:368 186:369 187:370 188:371 189:372 190:373 191:374 192:375 193:376 194:377 195:378 196:379 197:380 198:380 199:380 200:380 201:381 202:381 203:382 204:383 205:384 206:386 207:386 208:386 209:386 210:386 211:387 212:388 213:389 214:390 215:390 216:390 217:390 218:390 219:391 220:392 221:393 222:394 223:395 224:396 225:397 226:398 227:399 228:400 229:400 230:404 231:405 232:406 233:407 234:408 235:409 236:410 237:414 238:414 239:415 240:416 241:417 242:418 243:419 244:420 245:421 246:422 247:423 248:424 249:425 250:425 251:426 252:426 253:426 254:426 255:427 256:427 257:428 258:429 259:430 260:430 261:431 262:431 263:431 264:431 265:431 266:432 267:432 268:433 269:434 270:435 271:437 272:437 273:438 274:439 275:440 276:441 277:442 278:442 279:442 280:442 281:442 282:443 283:443 284:444 285:445 286:446 287:447 288:448 289:449 290:450 291:451 292:452 293:453 294:454 295:454 296:455 297:456 298:456 299:457 300:457 301:457 302:458 303:458 304:459 305:460 306:462 307:463 308:464 309:465 310:465 311:465 312:465 313:465 314:466 315:466 316:467 317:468 318:468 319:469 320:470 321:471 322:472 323:473 324:474 325:475 326:476 327:476 328:476 329:477 330:478 331:478 332:479 333:479 334:479 335:479 336:480 337:480 338:480 339:484 340:485 341:486 342:487 343:488 344:488 345:489 346:490 347:490 348:490 349:491 350:492 351:493 352:494 353:495 354:496 355:497 356:498 357:498 358:499 359:500 360:501 361:503 362:503 363:504 364:505 365:506 366:507 367:508 368:509 369:509 370:509 371:510 372:511 373:512 374:513 375:514 376:515 377:516 378:517 379:518 380:519 381:519 382:520 383:522 384:523 385:524 386:525 387:526 388:527 389:528 390:529 391:530 392:531 393:532 394:533 395:534 396:535 397:536 398:537 399:537 400:538 401:539 402:540 403:541 404:542 405:544 406:544 407:548 408:549 409:550 410:551 411:552 412:553 413:553 414:554 415:555 416:556 417:557 418:558 419:559 420:560 421:561 422:561 423:561 424:563 425:564 426:564 427:567 428:568 429:569 430:570 431:571 432:572 433:572 434:573 435:574 436:574 437:575 438:576 439:577 440:577 441:578 442:579 443:580 444:581 445:582 446:583 447:584 448:586 449:587 450:588 451:588 452:588 453:589 454:589 455:589 456:590 457:591 458:592 459:593 460:594 461:594 462:595 463:595 464:596 465:597 466:598 467:599 468:599 469:600 470:600 471:601 472:602 473:602 474:603 475:607 476:608 477:608 478:609 479:610 480:611 481:612 482:613 483:614 484:615 485:616 486:617 487:618 488:619 489:620 490:620 491:621 492:622 493:623 494:625 495:626 496:627 497:628 498:628 499:628 500:629 501:630 502:631 503:632 504:632 505:633 506:634 507:635 508:636 509:637 510:638\n",
      "INFO:tensorflow:token_is_max_context: 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:False 134:False 135:False 136:False 137:False 138:False 139:False 140:False 141:False 142:False 143:False 144:False 145:False 146:False 147:False 148:False 149:False 150:False 151:False 152:False 153:False 154:False 155:False 156:False 157:False 158:False 159:False 160:False 161:False 162:False 163:False 164:False 165:False 166:False 167:False 168:False 169:False 170:False 171:False 172:False 173:False 174:False 175:False 176:False 177:False 178:False 179:False 180:False 181:False 182:False 183:False 184:False 185:False 186:False 187:False 188:False 189:False 190:False 191:False 192:False 193:False 194:False 195:False 196:False 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:True 331:True 332:True 333:True 334:True 335:True 336:True 337:True 338:True 339:True 340:True 341:True 342:True 343:True 344:True 345:True 346:True 347:True 348:True 349:True 350:True 351:True 352:True 353:True 354:True 355:True 356:True 357:True 358:True 359:True 360:True 361:True 362:True 363:True 364:True 365:True 366:True 367:True 368:True 369:True 370:True 371:True 372:True 373:True 374:True 375:True 376:True 377:True 378:True 379:True 380:True 381:True 382:True 383:True 384:True 385:True 386:True 387:True 388:True 389:True 390:True 391:True 392:True 393:True 394:True 395:True 396:True 397:True 398:True 399:True 400:True 401:True 402:True 403:True 404:True 405:True 406:True 407:True 408:True 409:True 410:True 411:True 412:True 413:True 414:True 415:True 416:True 417:True 418:True 419:True 420:True 421:True 422:True 423:True 424:True 425:True 426:True 427:True 428:True 429:True 430:True 431:True 432:True 433:True 434:True 435:True 436:True 437:True 438:True 439:True 440:True 441:True 442:True 443:True 444:True 445:True 446:True 447:True 448:True 449:True 450:True 451:True 452:True 453:True 454:True 455:True 456:True 457:True 458:True 459:True 460:True 461:True 462:True 463:True 464:True 465:True 466:True 467:True 468:True 469:True 470:True 471:True 472:True 473:True 474:True 475:True 476:True 477:True 478:True 479:True 480:True 481:True 482:True 483:True 484:True 485:True 486:True 487:True 488:True 489:True 490:True 491:True 492:True 493:True 494:True 495:True 496:True 497:True 498:True 499:True 500:True 501:True 502:True 503:True 504:True 505:True 506:True 507:True 508:True 509:True 510:True\n",
      "INFO:tensorflow:input_ids: 101 2054 2003 1996 2516 1997 1996 6254 1029 102 1017 1003 3930 1999 6702 2058 1996 10975 28471 2271 2095 1012 2174 1010 2115 2194 1005 1055 6702 3473 2011 1021 1003 4102 2000 2197 2095 1012 2582 1010 1999 1996 4610 2512 1011 21839 6903 1010 2073 2115 2194 3701 5748 1010 2007 7400 1999 1996 3541 3006 1010 2256 3006 3745 2038 3445 2000 4029 1003 2005 1996 3361 2095 2494 1011 5840 4102 2000 2861 1003 2197 2095 1012 16021 23270 2063 1997 7860 4320 2011 1996 3068 1999 3408 1997 2152 2110 2504 7773 1999 2433 1997 9542 1998 1013 2030 4443 4171 1025 20673 11533 15001 4531 2037 2126 2046 1996 4968 3006 1998 2007 1996 7375 1997 1996 1520 15001 1998 2060 9098 3688 1006 13574 1997 15147 1004 7816 1997 3119 1004 6236 1010 2537 1010 4425 1004 4353 1007 2552 1010 2494 1005 4621 2013 1015 1008 2089 1010 2432 1010 2115 2194 2003 2358 3089 6455 2000 3623 2049 4341 6702 1998 3006 3745 1010 2926 1999 2049 4563 6089 1012 11252 7427 1024 1996 11252 7427 2004 4844 2011 1996 2604 2005 3919 1998 3361 8735 1006 12170 19699 1007 6819 3207 2049 2344 6052 2385 1013 2260 1013 2526 2003 2108 7528 2938 11921 16761 6588 1012 1996 2968 2837 2003 8822 1996 5082 1997 1996 5679 1012 3361 2836 2007 4847 2000 6515 2836 1520 1996 4341 6599 1997 2115 2194 2076 1996 2095 2001 2012 12667 1012 24559 21472 1012 2385 18749 2015 2004 2114 2004 1012 1002 26871 2692 1012 6365 18749 2015 1999 1996 3025 2095 1010 4760 1037 6689 1997 1020 1012 4229 1003 1010 2174 1010 1996 5618 2044 4171 2005 1996 2095 3445 2011 2105 5401 1003 2013 27424 1010 28245 1012 2570 18749 2015 1999 1996 3025 2095 2000 2010 1012 25374 1012 5824 18749 2015 2023 2095 1012 1996 9167 6599 7013 2076 1996 2095 2494 1011 5840 2001 27424 1012 22884 2692 1012 6021 18749 2015 1012 2023 2836 2038 2042 4762 3709 6970 4862 2050 1010 2011 2536 3740 2047 5821 11107 7682 5909 1010 2029 2038 4423 1520 2256 7325 2918 4237 2013 1996 7367 26061 2072 3465 7494 5761 10607 2011 2115 2194 1999 2049 3136 1010 2115 2194 4247 2000 2031 1996 2309 2922 4435 1999 1996 7163 15001 6903 1999 1996 2406 1010 11328 5815 2000 2049 3006 3745 1012 1999 3193 1997 1996 14830 6409 1010 2115 5501 2024 4039 2000 16755 1037 11443 4859 1012 4964 12816 1024 2045 2024 2053 4964 12816 2349 2015 14223 24565 3672 2011 1996 2194 1012 3037 2489 5857 2031 2042 2363 2013 9228 2875 1520 26512 1521 6691 1521 1010 2004 2856 2011 1996 12170 19699 6819 3207 2049 2344 6052 2385 1000 2285 1010 2526 10439 22046 1996 11252 5679 1012 1996 2194 2038 4162 2000 1996 2533 1997 2194 3821 2005 11819 2075 2122 28258 2013 8910 1997 2930 1055 2620 2050 1997 1996 3316 2552 1010 3838 1998 2060 12711 3513 1998 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000003\n",
      "INFO:tensorflow:example_index: 0\n",
      "INFO:tensorflow:doc_span_index: 3\n",
      "INFO:tensorflow:tokens: [CLS] what is the title of the document ? [SEP] trade & commerce , production , supply & distribution ) act , 2003 ' effective from 1 * may , 2004 , your company is st ##ri ##ving to increase its sales volumes and market share , especially in its core markets . rehabilitation package : the rehabilitation package as approved by the board for industrial and financial reconstruction ( bi ##fr ) vi ##de its order dated 16 / 12 / 2002 is being implemented sat ##ista ##ctor ##ily . the management committee is monitoring the progress of the scheme . financial performance with respect to operational performance ‘ the sales revenue of your company during the year was at rs . 307 ##46 . 16 lac ##s as against as . $ 284 ##0 . 94 lac ##s in the previous year , showing a decline of 6 . 38 % , however , the profit after tax for the year increased by around 57 % from fis , 475 . 22 lac ##s in the previous year to his . 747 . 72 lac ##s this year . the export revenue generated during the year 2003 - 04 was fis . 243 ##0 . 03 lac ##s . this performance has been fuel ##led inter ali ##a , by various planned new marketing initiatives bearing fruit , which has expanded ‘ our consumer base apart from the se ##vera ##i cost saving measures undertaken by your company in its operations , your company continues to have the single largest brand in the mini cigarettes segment in the country , steadily adding to its market share . in view of the accumulated losses , your directors are unable to recommend a divide ##nd . fixed deposit : there are no fixed deposit due ##s pending repay ##ment by the company . interest free contributions have been received from associates towards ‘ promoters ’ contribution ’ , as directed by the bi ##fr vi ##de its order dated 16 \" december , 2002 app ##roving the rehabilitation scheme . the company has applied to the department of company affairs for exempt ##ing these receipts from provisions of section s ##8 ##a of the companies act , 1956 and other applicable rules and provisions [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 10:327 11:328 12:329 13:329 14:330 15:330 16:331 17:332 18:333 19:333 20:334 21:334 22:335 23:335 24:336 25:337 26:339 27:339 28:340 29:340 30:341 31:341 32:342 33:343 34:344 35:345 36:345 37:345 38:346 39:347 40:348 41:349 42:350 43:351 44:352 45:353 46:353 47:354 48:355 49:356 50:357 51:358 52:358 53:362 54:363 55:363 56:367 57:368 58:369 59:370 60:371 61:372 62:373 63:374 64:375 65:376 66:377 67:378 68:379 69:380 70:380 71:380 72:380 73:381 74:381 75:382 76:383 77:384 78:386 79:386 80:386 81:386 82:386 83:387 84:388 85:389 86:390 87:390 88:390 89:390 90:390 91:391 92:392 93:393 94:394 95:395 96:396 97:397 98:398 99:399 100:400 101:400 102:404 103:405 104:406 105:407 106:408 107:409 108:410 109:414 110:414 111:415 112:416 113:417 114:418 115:419 116:420 117:421 118:422 119:423 120:424 121:425 122:425 123:426 124:426 125:426 126:426 127:427 128:427 129:428 130:429 131:430 132:430 133:431 134:431 135:431 136:431 137:431 138:432 139:432 140:433 141:434 142:435 143:437 144:437 145:438 146:439 147:440 148:441 149:442 150:442 151:442 152:442 153:442 154:443 155:443 156:444 157:445 158:446 159:447 160:448 161:449 162:450 163:451 164:452 165:453 166:454 167:454 168:455 169:456 170:456 171:457 172:457 173:457 174:458 175:458 176:459 177:460 178:462 179:463 180:464 181:465 182:465 183:465 184:465 185:465 186:466 187:466 188:467 189:468 190:468 191:469 192:470 193:471 194:472 195:473 196:474 197:475 198:476 199:476 200:476 201:477 202:478 203:478 204:479 205:479 206:479 207:479 208:480 209:480 210:480 211:484 212:485 213:486 214:487 215:488 216:488 217:489 218:490 219:490 220:490 221:491 222:492 223:493 224:494 225:495 226:496 227:497 228:498 229:498 230:499 231:500 232:501 233:503 234:503 235:504 236:505 237:506 238:507 239:508 240:509 241:509 242:509 243:510 244:511 245:512 246:513 247:514 248:515 249:516 250:517 251:518 252:519 253:519 254:520 255:522 256:523 257:524 258:525 259:526 260:527 261:528 262:529 263:530 264:531 265:532 266:533 267:534 268:535 269:536 270:537 271:537 272:538 273:539 274:540 275:541 276:542 277:544 278:544 279:548 280:549 281:550 282:551 283:552 284:553 285:553 286:554 287:555 288:556 289:557 290:558 291:559 292:560 293:561 294:561 295:561 296:563 297:564 298:564 299:567 300:568 301:569 302:570 303:571 304:572 305:572 306:573 307:574 308:574 309:575 310:576 311:577 312:577 313:578 314:579 315:580 316:581 317:582 318:583 319:584 320:586 321:587 322:588 323:588 324:588 325:589 326:589 327:589 328:590 329:591 330:592 331:593 332:594 333:594 334:595 335:595 336:596 337:597 338:598 339:599 340:599 341:600 342:600 343:601 344:602 345:602 346:603 347:607 348:608 349:608 350:609 351:610 352:611 353:612 354:613 355:614 356:615 357:616 358:617 359:618 360:619 361:620 362:620 363:621 364:622 365:623 366:625 367:626 368:627 369:628 370:628 371:628 372:629 373:630 374:631 375:632 376:632 377:633 378:634 379:635 380:636 381:637 382:638 383:639\n",
      "INFO:tensorflow:token_is_max_context: 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:False 134:False 135:False 136:False 137:False 138:False 139:False 140:False 141:False 142:False 143:False 144:False 145:False 146:False 147:False 148:False 149:False 150:False 151:False 152:False 153:False 154:False 155:False 156:False 157:False 158:False 159:False 160:False 161:False 162:False 163:False 164:False 165:False 166:False 167:False 168:False 169:False 170:False 171:False 172:False 173:False 174:False 175:False 176:False 177:False 178:False 179:False 180:False 181:False 182:False 183:False 184:False 185:False 186:False 187:False 188:False 189:False 190:False 191:False 192:False 193:False 194:False 195:False 196:False 197:False 198:False 199:False 200:False 201:False 202:False 203:False 204:False 205:False 206:False 207:False 208:False 209:False 210:False 211:False 212:False 213:False 214:False 215:False 216:False 217:False 218:False 219:False 220:False 221:False 222:False 223:False 224:False 225:False 226:False 227:False 228:False 229:False 230:False 231:False 232:False 233:False 234:False 235:False 236:False 237:False 238:False 239:False 240:False 241:False 242:False 243:False 244:False 245:False 246:False 247:False 248:False 249:False 250:False 251:False 252:False 253:False 254:False 255:False 256:False 257:False 258:False 259:False 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False 383:True\n",
      "INFO:tensorflow:input_ids: 101 2054 2003 1996 2516 1997 1996 6254 1029 102 3119 1004 6236 1010 2537 1010 4425 1004 4353 1007 2552 1010 2494 1005 4621 2013 1015 1008 2089 1010 2432 1010 2115 2194 2003 2358 3089 6455 2000 3623 2049 4341 6702 1998 3006 3745 1010 2926 1999 2049 4563 6089 1012 11252 7427 1024 1996 11252 7427 2004 4844 2011 1996 2604 2005 3919 1998 3361 8735 1006 12170 19699 1007 6819 3207 2049 2344 6052 2385 1013 2260 1013 2526 2003 2108 7528 2938 11921 16761 6588 1012 1996 2968 2837 2003 8822 1996 5082 1997 1996 5679 1012 3361 2836 2007 4847 2000 6515 2836 1520 1996 4341 6599 1997 2115 2194 2076 1996 2095 2001 2012 12667 1012 24559 21472 1012 2385 18749 2015 2004 2114 2004 1012 1002 26871 2692 1012 6365 18749 2015 1999 1996 3025 2095 1010 4760 1037 6689 1997 1020 1012 4229 1003 1010 2174 1010 1996 5618 2044 4171 2005 1996 2095 3445 2011 2105 5401 1003 2013 27424 1010 28245 1012 2570 18749 2015 1999 1996 3025 2095 2000 2010 1012 25374 1012 5824 18749 2015 2023 2095 1012 1996 9167 6599 7013 2076 1996 2095 2494 1011 5840 2001 27424 1012 22884 2692 1012 6021 18749 2015 1012 2023 2836 2038 2042 4762 3709 6970 4862 2050 1010 2011 2536 3740 2047 5821 11107 7682 5909 1010 2029 2038 4423 1520 2256 7325 2918 4237 2013 1996 7367 26061 2072 3465 7494 5761 10607 2011 2115 2194 1999 2049 3136 1010 2115 2194 4247 2000 2031 1996 2309 2922 4435 1999 1996 7163 15001 6903 1999 1996 2406 1010 11328 5815 2000 2049 3006 3745 1012 1999 3193 1997 1996 14830 6409 1010 2115 5501 2024 4039 2000 16755 1037 11443 4859 1012 4964 12816 1024 2045 2024 2053 4964 12816 2349 2015 14223 24565 3672 2011 1996 2194 1012 3037 2489 5857 2031 2042 2363 2013 9228 2875 1520 26512 1521 6691 1521 1010 2004 2856 2011 1996 12170 19699 6819 3207 2049 2344 6052 2385 1000 2285 1010 2526 10439 22046 1996 11252 5679 1012 1996 2194 2038 4162 2000 1996 2533 1997 2194 3821 2005 11819 2075 2122 28258 2013 8910 1997 2930 1055 2620 2050 1997 1996 3316 2552 1010 3838 1998 2060 12711 3513 1998 8910 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000004\n",
      "INFO:tensorflow:example_index: 1\n",
      "INFO:tensorflow:doc_span_index: 0\n",
      "INFO:tensorflow:tokens: [CLS] what is the numerical interest ? [SEP] @ tt . management report of the directors an discussion & analysis your directors here ##by submit their forty eighth annual report with the audit ##ed accounts for the year ended 31 \" march , 2004 . summary of financial result : for the year for the year ended ended 31 . 03 . 2004 31 . 03 . 2003 ( rs . in lac ##s ) profit for the year before interest , de ##pre ##ciation and exceptional items : 296 ##1 . 59 269 ##7 . 42 interest 41 ##45 / 90 104 ##7 - 79 de ##pre ##ciation 240 . 76 281 . 73 profit bo ##for ##e tax and exceptional items 1874 . 93 136 ##7 . 90 exceptional te ##ms ( 289 . 65 ) ( 48 ##4 . 68 ) de ##pre ##ciation of eat ##lier yo ##ars — ( 145 . 94 ) prof ##il before taxation 128 ##5 . 28 76 ##7 . 28 provision for taxation current tax ( wealth tax ) 5 . 75 5 . 09 deter ##red tax 53 ##1 - 81 286 . 97 profit after taxation 747 . 72 475 . 22 amount transferred from de ##ben ##ture redemption reserve — 350 . 00 balance brought forward from last year ( 309 ##8 . 08 ) ( 139 ##23 . 30 ) balance of loss carried over to balance sheet ( 123 ##50 . 36 ) ( 130 ##9 ##8 . 08 ) industry structure and development : the industry posted a 3 % growth in volumes over the pr ##avio ##us year . however , your company ' s volumes grew by 7 % compared to last year . further , in the economy non - filtered segment , where your company mainly operates , with thrust in the rural market , our market share has increased to 36 % for the financial year 2003 - 04 compared to 31 % last year . ins ##pit ##e of challenges faced by the industry in terms of high state level taxes in form of luxury and / or entry tax ; smug ##gled cigarettes finding their way into the domestic market and with the implementation of the ‘ cigarettes and other tobacco products ( prohibition of advertisement & regulation of trade & commerce , production , supply & distribution ) act , 2003 ' effective from 1 * may , 2004 , your company is st ##ri ##ving to increase its sales volumes and market share , especially in its core markets . rehabilitation package : the rehabilitation package as approved by the board for industrial and financial reconstruction ( bi ##fr ) vi ##de its order dated 16 / 12 / 2002 is being implemented sat ##ista ##ctor ##ily . the management committee is monitoring the progress of the scheme . financial performance with respect to operational performance ‘ the sales revenue of your company during the year was at rs . 307 ##46 . 16 lac ##s [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 8:4 9:4 10:4 11:8 12:28 13:29 14:30 15:31 16:32 17:34 18:35 19:36 20:40 21:41 22:42 23:42 24:43 25:44 26:45 27:46 28:47 29:48 30:49 31:50 32:51 33:51 34:52 35:53 36:54 37:55 38:56 39:57 40:57 41:58 42:58 43:59 44:59 45:67 46:68 47:69 48:70 49:70 50:78 51:79 52:80 53:81 54:82 55:83 56:85 57:86 58:88 59:88 60:88 61:88 62:88 63:89 64:89 65:89 66:89 67:89 68:93 69:93 70:93 71:94 72:95 73:95 74:95 75:99 76:100 77:101 78:102 79:103 80:104 81:104 82:108 83:108 84:108 85:109 86:110 87:111 88:111 89:112 90:112 91:112 92:112 93:113 94:113 95:113 96:113 97:115 98:116 99:116 100:116 101:116 102:117 103:117 104:117 105:117 106:119 107:119 108:119 109:120 110:120 111:120 112:121 113:121 114:121 115:123 116:124 117:124 118:124 119:125 120:126 121:127 122:128 123:129 124:129 125:129 126:130 127:130 128:130 129:130 130:132 131:133 132:133 133:134 134:134 135:134 136:134 137:134 138:135 139:135 140:135 141:135 142:135 143:135 144:137 145:137 146:137 147:138 148:139 149:139 150:140 151:140 152:141 153:142 154:142 155:142 156:142 157:142 158:144 159:144 160:145 161:146 162:147 163:147 164:147 165:147 166:148 167:148 168:148 169:148 170:150 171:151 172:152 173:155 174:156 175:157 176:157 177:158 178:158 179:159 180:159 181:159 182:160 183:160 184:160 185:162 186:162 187:163 188:164 189:164 190:164 191:164 192:165 193:165 194:165 195:167 196:168 197:169 198:170 199:170 200:170 201:171 202:171 203:171 204:173 205:174 206:175 207:176 208:176 209:176 210:177 211:178 212:179 213:180 214:180 215:180 216:182 217:183 218:184 219:185 220:186 221:187 222:188 223:188 224:188 225:188 226:188 227:188 228:189 229:189 230:189 231:189 232:189 233:189 234:191 235:192 236:193 237:194 238:195 239:196 240:197 241:198 242:199 243:199 244:199 245:199 246:199 247:199 248:200 249:200 250:200 251:200 252:200 253:200 254:200 255:208 256:209 257:210 258:211 259:211 260:215 261:216 262:217 263:218 264:219 265:219 266:220 267:221 268:222 269:223 270:224 271:225 272:225 273:225 274:226 275:226 276:227 277:227 278:228 279:229 280:229 281:229 282:230 283:231 284:232 285:233 286:233 287:234 288:235 289:237 290:238 291:238 292:239 293:239 294:240 295:241 296:242 297:243 298:243 299:243 300:244 301:244 302:245 303:246 304:247 305:248 306:249 307:249 308:250 309:251 310:252 311:253 312:254 313:255 314:255 315:256 316:258 317:259 318:260 319:261 320:262 321:263 322:263 323:264 324:265 325:266 326:267 327:268 328:268 329:268 330:269 331:270 332:271 333:271 334:272 335:273 336:273 337:277 338:277 339:277 340:278 341:279 342:280 343:281 344:282 345:283 346:284 347:285 348:286 349:287 350:288 351:289 352:290 353:291 354:292 355:293 356:294 357:295 358:295 359:296 360:297 361:298 362:298 363:299 364:299 365:301 366:302 367:303 368:304 369:305 370:306 371:307 372:308 373:309 374:310 375:311 376:312 377:313 378:314 379:315 380:315 381:316 382:317 383:318 384:319 385:321 386:321 387:322 388:323 389:324 390:325 391:326 392:327 393:328 394:329 395:329 396:330 397:330 398:331 399:332 400:333 401:333 402:334 403:334 404:335 405:335 406:336 407:337 408:339 409:339 410:340 411:340 412:341 413:341 414:342 415:343 416:344 417:345 418:345 419:345 420:346 421:347 422:348 423:349 424:350 425:351 426:352 427:353 428:353 429:354 430:355 431:356 432:357 433:358 434:358 435:362 436:363 437:363 438:367 439:368 440:369 441:370 442:371 443:372 444:373 445:374 446:375 447:376 448:377 449:378 450:379 451:380 452:380 453:380 454:380 455:381 456:381 457:382 458:383 459:384 460:386 461:386 462:386 463:386 464:386 465:387 466:388 467:389 468:390 469:390 470:390 471:390 472:390 473:391 474:392 475:393 476:394 477:395 478:396 479:397 480:398 481:399 482:400 483:400 484:404 485:405 486:406 487:407 488:408 489:409 490:410 491:414 492:414 493:415 494:416 495:417 496:418 497:419 498:420 499:421 500:422 501:423 502:424 503:425 504:425 505:426 506:426 507:426 508:426 509:427 510:427\n",
      "INFO:tensorflow:token_is_max_context: 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False 383:False 384:False 385:False 386:False 387:False 388:False 389:False 390:False 391:False 392:False 393:False 394:False 395:False 396:False 397:False 398:False 399:False 400:False 401:False 402:False 403:False 404:False 405:False 406:False 407:False 408:False 409:False 410:False 411:False 412:False 413:False 414:False 415:False 416:False 417:False 418:False 419:False 420:False 421:False 422:False 423:False 424:False 425:False 426:False 427:False 428:False 429:False 430:False 431:False 432:False 433:False 434:False 435:False 436:False 437:False 438:False 439:False 440:False 441:False 442:False 443:False 444:False 445:False 446:False 447:False 448:False 449:False 450:False 451:False 452:False 453:False 454:False 455:False 456:False 457:False 458:False 459:False 460:False 461:False 462:False 463:False 464:False 465:False 466:False 467:False 468:False 469:False 470:False 471:False 472:False 473:False 474:False 475:False 476:False 477:False 478:False 479:False 480:False 481:False 482:False 483:False 484:False 485:False 486:False 487:False 488:False 489:False 490:False 491:False 492:False 493:False 494:False 495:False 496:False 497:False 498:False 499:False 500:False 501:False 502:False 503:False 504:False 505:False 506:False 507:False 508:False 509:False 510:False\n",
      "INFO:tensorflow:input_ids: 101 2054 2003 1996 15973 3037 1029 102 1030 23746 1012 2968 3189 1997 1996 5501 2019 6594 1004 4106 2115 5501 2182 3762 12040 2037 5659 5964 3296 3189 2007 1996 15727 2098 6115 2005 1996 2095 3092 2861 1000 2233 1010 2432 1012 12654 1997 3361 2765 1024 2005 1996 2095 2005 1996 2095 3092 3092 2861 1012 6021 1012 2432 2861 1012 6021 1012 2494 1006 12667 1012 1999 18749 2015 1007 5618 2005 1996 2095 2077 3037 1010 2139 28139 23247 1998 11813 5167 1024 27200 2487 1012 5354 25717 2581 1012 4413 3037 4601 19961 1013 3938 9645 2581 1011 6535 2139 28139 23247 11212 1012 6146 22955 1012 6421 5618 8945 29278 2063 4171 1998 11813 5167 7586 1012 6109 15407 2581 1012 3938 11813 8915 5244 1006 27054 1012 3515 1007 1006 4466 2549 1012 6273 1007 2139 28139 23247 1997 4521 14355 10930 11650 1517 1006 13741 1012 6365 1007 11268 4014 2077 14952 11899 2629 1012 2654 6146 2581 1012 2654 9347 2005 14952 2783 4171 1006 7177 4171 1007 1019 1012 4293 1019 1012 5641 28283 5596 4171 5187 2487 1011 6282 24921 1012 5989 5618 2044 14952 25374 1012 5824 28245 1012 2570 3815 4015 2013 2139 10609 11244 18434 3914 1517 8698 1012 4002 5703 2716 2830 2013 2197 2095 1006 25048 2620 1012 5511 1007 1006 16621 21926 1012 2382 1007 5703 1997 3279 3344 2058 2000 5703 7123 1006 13138 12376 1012 4029 1007 1006 7558 2683 2620 1012 5511 1007 3068 3252 1998 2458 1024 1996 3068 6866 1037 1017 1003 3930 1999 6702 2058 1996 10975 28471 2271 2095 1012 2174 1010 2115 2194 1005 1055 6702 3473 2011 1021 1003 4102 2000 2197 2095 1012 2582 1010 1999 1996 4610 2512 1011 21839 6903 1010 2073 2115 2194 3701 5748 1010 2007 7400 1999 1996 3541 3006 1010 2256 3006 3745 2038 3445 2000 4029 1003 2005 1996 3361 2095 2494 1011 5840 4102 2000 2861 1003 2197 2095 1012 16021 23270 2063 1997 7860 4320 2011 1996 3068 1999 3408 1997 2152 2110 2504 7773 1999 2433 1997 9542 1998 1013 2030 4443 4171 1025 20673 11533 15001 4531 2037 2126 2046 1996 4968 3006 1998 2007 1996 7375 1997 1996 1520 15001 1998 2060 9098 3688 1006 13574 1997 15147 1004 7816 1997 3119 1004 6236 1010 2537 1010 4425 1004 4353 1007 2552 1010 2494 1005 4621 2013 1015 1008 2089 1010 2432 1010 2115 2194 2003 2358 3089 6455 2000 3623 2049 4341 6702 1998 3006 3745 1010 2926 1999 2049 4563 6089 1012 11252 7427 1024 1996 11252 7427 2004 4844 2011 1996 2604 2005 3919 1998 3361 8735 1006 12170 19699 1007 6819 3207 2049 2344 6052 2385 1013 2260 1013 2526 2003 2108 7528 2938 11921 16761 6588 1012 1996 2968 2837 2003 8822 1996 5082 1997 1996 5679 1012 3361 2836 2007 4847 2000 6515 2836 1520 1996 4341 6599 1997 2115 2194 2076 1996 2095 2001 2012 12667 1012 24559 21472 1012 2385 18749 2015 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000005\n",
      "INFO:tensorflow:example_index: 1\n",
      "INFO:tensorflow:doc_span_index: 1\n",
      "INFO:tensorflow:tokens: [CLS] what is the numerical interest ? [SEP] 65 ) ( 48 ##4 . 68 ) de ##pre ##ciation of eat ##lier yo ##ars — ( 145 . 94 ) prof ##il before taxation 128 ##5 . 28 76 ##7 . 28 provision for taxation current tax ( wealth tax ) 5 . 75 5 . 09 deter ##red tax 53 ##1 - 81 286 . 97 profit after taxation 747 . 72 475 . 22 amount transferred from de ##ben ##ture redemption reserve — 350 . 00 balance brought forward from last year ( 309 ##8 . 08 ) ( 139 ##23 . 30 ) balance of loss carried over to balance sheet ( 123 ##50 . 36 ) ( 130 ##9 ##8 . 08 ) industry structure and development : the industry posted a 3 % growth in volumes over the pr ##avio ##us year . however , your company ' s volumes grew by 7 % compared to last year . further , in the economy non - filtered segment , where your company mainly operates , with thrust in the rural market , our market share has increased to 36 % for the financial year 2003 - 04 compared to 31 % last year . ins ##pit ##e of challenges faced by the industry in terms of high state level taxes in form of luxury and / or entry tax ; smug ##gled cigarettes finding their way into the domestic market and with the implementation of the ‘ cigarettes and other tobacco products ( prohibition of advertisement & regulation of trade & commerce , production , supply & distribution ) act , 2003 ' effective from 1 * may , 2004 , your company is st ##ri ##ving to increase its sales volumes and market share , especially in its core markets . rehabilitation package : the rehabilitation package as approved by the board for industrial and financial reconstruction ( bi ##fr ) vi ##de its order dated 16 / 12 / 2002 is being implemented sat ##ista ##ctor ##ily . the management committee is monitoring the progress of the scheme . financial performance with respect to operational performance ‘ the sales revenue of your company during the year was at rs . 307 ##46 . 16 lac ##s as against as . $ 284 ##0 . 94 lac ##s in the previous year , showing a decline of 6 . 38 % , however , the profit after tax for the year increased by around 57 % from fis , 475 . 22 lac ##s in the previous year to his . 747 . 72 lac ##s this year . the export revenue generated during the year 2003 - 04 was fis . 243 ##0 . 03 lac ##s . this performance has been fuel ##led inter ali ##a , by various planned new marketing initiatives bearing fruit , which has expanded ‘ our consumer base apart from the se ##vera ##i cost saving measures undertaken by your company in its operations , your company continues [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 8:134 9:134 10:135 11:135 12:135 13:135 14:135 15:135 16:137 17:137 18:137 19:138 20:139 21:139 22:140 23:140 24:141 25:142 26:142 27:142 28:142 29:142 30:144 31:144 32:145 33:146 34:147 35:147 36:147 37:147 38:148 39:148 40:148 41:148 42:150 43:151 44:152 45:155 46:156 47:157 48:157 49:158 50:158 51:159 52:159 53:159 54:160 55:160 56:160 57:162 58:162 59:163 60:164 61:164 62:164 63:164 64:165 65:165 66:165 67:167 68:168 69:169 70:170 71:170 72:170 73:171 74:171 75:171 76:173 77:174 78:175 79:176 80:176 81:176 82:177 83:178 84:179 85:180 86:180 87:180 88:182 89:183 90:184 91:185 92:186 93:187 94:188 95:188 96:188 97:188 98:188 99:188 100:189 101:189 102:189 103:189 104:189 105:189 106:191 107:192 108:193 109:194 110:195 111:196 112:197 113:198 114:199 115:199 116:199 117:199 118:199 119:199 120:200 121:200 122:200 123:200 124:200 125:200 126:200 127:208 128:209 129:210 130:211 131:211 132:215 133:216 134:217 135:218 136:219 137:219 138:220 139:221 140:222 141:223 142:224 143:225 144:225 145:225 146:226 147:226 148:227 149:227 150:228 151:229 152:229 153:229 154:230 155:231 156:232 157:233 158:233 159:234 160:235 161:237 162:238 163:238 164:239 165:239 166:240 167:241 168:242 169:243 170:243 171:243 172:244 173:244 174:245 175:246 176:247 177:248 178:249 179:249 180:250 181:251 182:252 183:253 184:254 185:255 186:255 187:256 188:258 189:259 190:260 191:261 192:262 193:263 194:263 195:264 196:265 197:266 198:267 199:268 200:268 201:268 202:269 203:270 204:271 205:271 206:272 207:273 208:273 209:277 210:277 211:277 212:278 213:279 214:280 215:281 216:282 217:283 218:284 219:285 220:286 221:287 222:288 223:289 224:290 225:291 226:292 227:293 228:294 229:295 230:295 231:296 232:297 233:298 234:298 235:299 236:299 237:301 238:302 239:303 240:304 241:305 242:306 243:307 244:308 245:309 246:310 247:311 248:312 249:313 250:314 251:315 252:315 253:316 254:317 255:318 256:319 257:321 258:321 259:322 260:323 261:324 262:325 263:326 264:327 265:328 266:329 267:329 268:330 269:330 270:331 271:332 272:333 273:333 274:334 275:334 276:335 277:335 278:336 279:337 280:339 281:339 282:340 283:340 284:341 285:341 286:342 287:343 288:344 289:345 290:345 291:345 292:346 293:347 294:348 295:349 296:350 297:351 298:352 299:353 300:353 301:354 302:355 303:356 304:357 305:358 306:358 307:362 308:363 309:363 310:367 311:368 312:369 313:370 314:371 315:372 316:373 317:374 318:375 319:376 320:377 321:378 322:379 323:380 324:380 325:380 326:380 327:381 328:381 329:382 330:383 331:384 332:386 333:386 334:386 335:386 336:386 337:387 338:388 339:389 340:390 341:390 342:390 343:390 344:390 345:391 346:392 347:393 348:394 349:395 350:396 351:397 352:398 353:399 354:400 355:400 356:404 357:405 358:406 359:407 360:408 361:409 362:410 363:414 364:414 365:415 366:416 367:417 368:418 369:419 370:420 371:421 372:422 373:423 374:424 375:425 376:425 377:426 378:426 379:426 380:426 381:427 382:427 383:428 384:429 385:430 386:430 387:431 388:431 389:431 390:431 391:431 392:432 393:432 394:433 395:434 396:435 397:437 398:437 399:438 400:439 401:440 402:441 403:442 404:442 405:442 406:442 407:442 408:443 409:443 410:444 411:445 412:446 413:447 414:448 415:449 416:450 417:451 418:452 419:453 420:454 421:454 422:455 423:456 424:456 425:457 426:457 427:457 428:458 429:458 430:459 431:460 432:462 433:463 434:464 435:465 436:465 437:465 438:465 439:465 440:466 441:466 442:467 443:468 444:468 445:469 446:470 447:471 448:472 449:473 450:474 451:475 452:476 453:476 454:476 455:477 456:478 457:478 458:479 459:479 460:479 461:479 462:480 463:480 464:480 465:484 466:485 467:486 468:487 469:488 470:488 471:489 472:490 473:490 474:490 475:491 476:492 477:493 478:494 479:495 480:496 481:497 482:498 483:498 484:499 485:500 486:501 487:503 488:503 489:504 490:505 491:506 492:507 493:508 494:509 495:509 496:509 497:510 498:511 499:512 500:513 501:514 502:515 503:516 504:517 505:518 506:519 507:519 508:520 509:522 510:523\n",
      "INFO:tensorflow:token_is_max_context: 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:False 134:False 135:False 136:False 137:False 138:False 139:False 140:False 141:False 142:False 143:False 144:False 145:False 146:False 147:False 148:False 149:False 150:False 151:False 152:False 153:False 154:False 155:False 156:False 157:False 158:False 159:False 160:False 161:False 162:False 163:False 164:False 165:False 166:False 167:False 168:False 169:False 170:False 171:False 172:False 173:False 174:False 175:False 176:False 177:False 178:False 179:False 180:False 181:False 182:False 183:False 184:False 185:False 186:False 187:False 188:False 189:False 190:False 191:False 192:False 193:False 194:False 195:False 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False 383:False 384:False 385:False 386:False 387:False 388:False 389:False 390:False 391:False 392:False 393:False 394:False 395:False 396:False 397:False 398:False 399:False 400:False 401:False 402:False 403:False 404:False 405:False 406:False 407:False 408:False 409:False 410:False 411:False 412:False 413:False 414:False 415:False 416:False 417:False 418:False 419:False 420:False 421:False 422:False 423:False 424:False 425:False 426:False 427:False 428:False 429:False 430:False 431:False 432:False 433:False 434:False 435:False 436:False 437:False 438:False 439:False 440:False 441:False 442:False 443:False 444:False 445:False 446:False 447:False 448:False 449:False 450:False 451:False 452:False 453:False 454:False 455:False 456:False 457:False 458:False 459:False 460:False 461:False 462:False 463:False 464:False 465:False 466:False 467:False 468:False 469:False 470:False 471:False 472:False 473:False 474:False 475:False 476:False 477:False 478:False 479:False 480:False 481:False 482:False 483:False 484:False 485:False 486:False 487:False 488:False 489:False 490:False 491:False 492:False 493:False 494:False 495:False 496:False 497:False 498:False 499:False 500:False 501:False 502:False 503:False 504:False 505:False 506:False 507:False 508:False 509:False 510:False\n",
      "INFO:tensorflow:input_ids: 101 2054 2003 1996 15973 3037 1029 102 3515 1007 1006 4466 2549 1012 6273 1007 2139 28139 23247 1997 4521 14355 10930 11650 1517 1006 13741 1012 6365 1007 11268 4014 2077 14952 11899 2629 1012 2654 6146 2581 1012 2654 9347 2005 14952 2783 4171 1006 7177 4171 1007 1019 1012 4293 1019 1012 5641 28283 5596 4171 5187 2487 1011 6282 24921 1012 5989 5618 2044 14952 25374 1012 5824 28245 1012 2570 3815 4015 2013 2139 10609 11244 18434 3914 1517 8698 1012 4002 5703 2716 2830 2013 2197 2095 1006 25048 2620 1012 5511 1007 1006 16621 21926 1012 2382 1007 5703 1997 3279 3344 2058 2000 5703 7123 1006 13138 12376 1012 4029 1007 1006 7558 2683 2620 1012 5511 1007 3068 3252 1998 2458 1024 1996 3068 6866 1037 1017 1003 3930 1999 6702 2058 1996 10975 28471 2271 2095 1012 2174 1010 2115 2194 1005 1055 6702 3473 2011 1021 1003 4102 2000 2197 2095 1012 2582 1010 1999 1996 4610 2512 1011 21839 6903 1010 2073 2115 2194 3701 5748 1010 2007 7400 1999 1996 3541 3006 1010 2256 3006 3745 2038 3445 2000 4029 1003 2005 1996 3361 2095 2494 1011 5840 4102 2000 2861 1003 2197 2095 1012 16021 23270 2063 1997 7860 4320 2011 1996 3068 1999 3408 1997 2152 2110 2504 7773 1999 2433 1997 9542 1998 1013 2030 4443 4171 1025 20673 11533 15001 4531 2037 2126 2046 1996 4968 3006 1998 2007 1996 7375 1997 1996 1520 15001 1998 2060 9098 3688 1006 13574 1997 15147 1004 7816 1997 3119 1004 6236 1010 2537 1010 4425 1004 4353 1007 2552 1010 2494 1005 4621 2013 1015 1008 2089 1010 2432 1010 2115 2194 2003 2358 3089 6455 2000 3623 2049 4341 6702 1998 3006 3745 1010 2926 1999 2049 4563 6089 1012 11252 7427 1024 1996 11252 7427 2004 4844 2011 1996 2604 2005 3919 1998 3361 8735 1006 12170 19699 1007 6819 3207 2049 2344 6052 2385 1013 2260 1013 2526 2003 2108 7528 2938 11921 16761 6588 1012 1996 2968 2837 2003 8822 1996 5082 1997 1996 5679 1012 3361 2836 2007 4847 2000 6515 2836 1520 1996 4341 6599 1997 2115 2194 2076 1996 2095 2001 2012 12667 1012 24559 21472 1012 2385 18749 2015 2004 2114 2004 1012 1002 26871 2692 1012 6365 18749 2015 1999 1996 3025 2095 1010 4760 1037 6689 1997 1020 1012 4229 1003 1010 2174 1010 1996 5618 2044 4171 2005 1996 2095 3445 2011 2105 5401 1003 2013 27424 1010 28245 1012 2570 18749 2015 1999 1996 3025 2095 2000 2010 1012 25374 1012 5824 18749 2015 2023 2095 1012 1996 9167 6599 7013 2076 1996 2095 2494 1011 5840 2001 27424 1012 22884 2692 1012 6021 18749 2015 1012 2023 2836 2038 2042 4762 3709 6970 4862 2050 1010 2011 2536 3740 2047 5821 11107 7682 5909 1010 2029 2038 4423 1520 2256 7325 2918 4237 2013 1996 7367 26061 2072 3465 7494 5761 10607 2011 2115 2194 1999 2049 3136 1010 2115 2194 4247 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000006\n",
      "INFO:tensorflow:example_index: 1\n",
      "INFO:tensorflow:doc_span_index: 2\n",
      "INFO:tensorflow:tokens: [CLS] what is the numerical interest ? [SEP] 3 % growth in volumes over the pr ##avio ##us year . however , your company ' s volumes grew by 7 % compared to last year . further , in the economy non - filtered segment , where your company mainly operates , with thrust in the rural market , our market share has increased to 36 % for the financial year 2003 - 04 compared to 31 % last year . ins ##pit ##e of challenges faced by the industry in terms of high state level taxes in form of luxury and / or entry tax ; smug ##gled cigarettes finding their way into the domestic market and with the implementation of the ‘ cigarettes and other tobacco products ( prohibition of advertisement & regulation of trade & commerce , production , supply & distribution ) act , 2003 ' effective from 1 * may , 2004 , your company is st ##ri ##ving to increase its sales volumes and market share , especially in its core markets . rehabilitation package : the rehabilitation package as approved by the board for industrial and financial reconstruction ( bi ##fr ) vi ##de its order dated 16 / 12 / 2002 is being implemented sat ##ista ##ctor ##ily . the management committee is monitoring the progress of the scheme . financial performance with respect to operational performance ‘ the sales revenue of your company during the year was at rs . 307 ##46 . 16 lac ##s as against as . $ 284 ##0 . 94 lac ##s in the previous year , showing a decline of 6 . 38 % , however , the profit after tax for the year increased by around 57 % from fis , 475 . 22 lac ##s in the previous year to his . 747 . 72 lac ##s this year . the export revenue generated during the year 2003 - 04 was fis . 243 ##0 . 03 lac ##s . this performance has been fuel ##led inter ali ##a , by various planned new marketing initiatives bearing fruit , which has expanded ‘ our consumer base apart from the se ##vera ##i cost saving measures undertaken by your company in its operations , your company continues to have the single largest brand in the mini cigarettes segment in the country , steadily adding to its market share . in view of the accumulated losses , your directors are unable to recommend a divide ##nd . fixed deposit : there are no fixed deposit due ##s pending repay ##ment by the company . interest free contributions have been received from associates towards ‘ promoters ’ contribution ’ , as directed by the bi ##fr vi ##de its order dated 16 \" december , 2002 app ##roving the rehabilitation scheme . the company has applied to the department of company affairs for exempt ##ing these receipts from provisions of section s ##8 ##a of the companies act , 1956 and other applicable rules and provisions [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 8:219 9:219 10:220 11:221 12:222 13:223 14:224 15:225 16:225 17:225 18:226 19:226 20:227 21:227 22:228 23:229 24:229 25:229 26:230 27:231 28:232 29:233 30:233 31:234 32:235 33:237 34:238 35:238 36:239 37:239 38:240 39:241 40:242 41:243 42:243 43:243 44:244 45:244 46:245 47:246 48:247 49:248 50:249 51:249 52:250 53:251 54:252 55:253 56:254 57:255 58:255 59:256 60:258 61:259 62:260 63:261 64:262 65:263 66:263 67:264 68:265 69:266 70:267 71:268 72:268 73:268 74:269 75:270 76:271 77:271 78:272 79:273 80:273 81:277 82:277 83:277 84:278 85:279 86:280 87:281 88:282 89:283 90:284 91:285 92:286 93:287 94:288 95:289 96:290 97:291 98:292 99:293 100:294 101:295 102:295 103:296 104:297 105:298 106:298 107:299 108:299 109:301 110:302 111:303 112:304 113:305 114:306 115:307 116:308 117:309 118:310 119:311 120:312 121:313 122:314 123:315 124:315 125:316 126:317 127:318 128:319 129:321 130:321 131:322 132:323 133:324 134:325 135:326 136:327 137:328 138:329 139:329 140:330 141:330 142:331 143:332 144:333 145:333 146:334 147:334 148:335 149:335 150:336 151:337 152:339 153:339 154:340 155:340 156:341 157:341 158:342 159:343 160:344 161:345 162:345 163:345 164:346 165:347 166:348 167:349 168:350 169:351 170:352 171:353 172:353 173:354 174:355 175:356 176:357 177:358 178:358 179:362 180:363 181:363 182:367 183:368 184:369 185:370 186:371 187:372 188:373 189:374 190:375 191:376 192:377 193:378 194:379 195:380 196:380 197:380 198:380 199:381 200:381 201:382 202:383 203:384 204:386 205:386 206:386 207:386 208:386 209:387 210:388 211:389 212:390 213:390 214:390 215:390 216:390 217:391 218:392 219:393 220:394 221:395 222:396 223:397 224:398 225:399 226:400 227:400 228:404 229:405 230:406 231:407 232:408 233:409 234:410 235:414 236:414 237:415 238:416 239:417 240:418 241:419 242:420 243:421 244:422 245:423 246:424 247:425 248:425 249:426 250:426 251:426 252:426 253:427 254:427 255:428 256:429 257:430 258:430 259:431 260:431 261:431 262:431 263:431 264:432 265:432 266:433 267:434 268:435 269:437 270:437 271:438 272:439 273:440 274:441 275:442 276:442 277:442 278:442 279:442 280:443 281:443 282:444 283:445 284:446 285:447 286:448 287:449 288:450 289:451 290:452 291:453 292:454 293:454 294:455 295:456 296:456 297:457 298:457 299:457 300:458 301:458 302:459 303:460 304:462 305:463 306:464 307:465 308:465 309:465 310:465 311:465 312:466 313:466 314:467 315:468 316:468 317:469 318:470 319:471 320:472 321:473 322:474 323:475 324:476 325:476 326:476 327:477 328:478 329:478 330:479 331:479 332:479 333:479 334:480 335:480 336:480 337:484 338:485 339:486 340:487 341:488 342:488 343:489 344:490 345:490 346:490 347:491 348:492 349:493 350:494 351:495 352:496 353:497 354:498 355:498 356:499 357:500 358:501 359:503 360:503 361:504 362:505 363:506 364:507 365:508 366:509 367:509 368:509 369:510 370:511 371:512 372:513 373:514 374:515 375:516 376:517 377:518 378:519 379:519 380:520 381:522 382:523 383:524 384:525 385:526 386:527 387:528 388:529 389:530 390:531 391:532 392:533 393:534 394:535 395:536 396:537 397:537 398:538 399:539 400:540 401:541 402:542 403:544 404:544 405:548 406:549 407:550 408:551 409:552 410:553 411:553 412:554 413:555 414:556 415:557 416:558 417:559 418:560 419:561 420:561 421:561 422:563 423:564 424:564 425:567 426:568 427:569 428:570 429:571 430:572 431:572 432:573 433:574 434:574 435:575 436:576 437:577 438:577 439:578 440:579 441:580 442:581 443:582 444:583 445:584 446:586 447:587 448:588 449:588 450:588 451:589 452:589 453:589 454:590 455:591 456:592 457:593 458:594 459:594 460:595 461:595 462:596 463:597 464:598 465:599 466:599 467:600 468:600 469:601 470:602 471:602 472:603 473:607 474:608 475:608 476:609 477:610 478:611 479:612 480:613 481:614 482:615 483:616 484:617 485:618 486:619 487:620 488:620 489:621 490:622 491:623 492:625 493:626 494:627 495:628 496:628 497:628 498:629 499:630 500:631 501:632 502:632 503:633 504:634 505:635 506:636 507:637 508:638 509:639\n",
      "INFO:tensorflow:token_is_max_context: 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:False 134:False 135:False 136:False 137:False 138:False 139:False 140:False 141:False 142:False 143:False 144:False 145:False 146:False 147:False 148:False 149:False 150:False 151:False 152:False 153:False 154:False 155:False 156:False 157:False 158:False 159:False 160:False 161:False 162:False 163:False 164:False 165:False 166:False 167:False 168:False 169:False 170:False 171:False 172:False 173:False 174:False 175:False 176:False 177:False 178:False 179:False 180:False 181:False 182:False 183:False 184:False 185:False 186:False 187:False 188:False 189:False 190:False 191:False 192:False 193:False 194:False 195:False 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:True 331:True 332:True 333:True 334:True 335:True 336:True 337:True 338:True 339:True 340:True 341:True 342:True 343:True 344:True 345:True 346:True 347:True 348:True 349:True 350:True 351:True 352:True 353:True 354:True 355:True 356:True 357:True 358:True 359:True 360:True 361:True 362:True 363:True 364:True 365:True 366:True 367:True 368:True 369:True 370:True 371:True 372:True 373:True 374:True 375:True 376:True 377:True 378:True 379:True 380:True 381:True 382:True 383:True 384:True 385:True 386:True 387:True 388:True 389:True 390:True 391:True 392:True 393:True 394:True 395:True 396:True 397:True 398:True 399:True 400:True 401:True 402:True 403:True 404:True 405:True 406:True 407:True 408:True 409:True 410:True 411:True 412:True 413:True 414:True 415:True 416:True 417:True 418:True 419:True 420:True 421:True 422:True 423:True 424:True 425:True 426:True 427:True 428:True 429:True 430:True 431:True 432:True 433:True 434:True 435:True 436:True 437:True 438:True 439:True 440:True 441:True 442:True 443:True 444:True 445:True 446:True 447:True 448:True 449:True 450:True 451:True 452:True 453:True 454:True 455:True 456:True 457:True 458:True 459:True 460:True 461:True 462:True 463:True 464:True 465:True 466:True 467:True 468:True 469:True 470:True 471:True 472:True 473:True 474:True 475:True 476:True 477:True 478:True 479:True 480:True 481:True 482:True 483:True 484:True 485:True 486:True 487:True 488:True 489:True 490:True 491:True 492:True 493:True 494:True 495:True 496:True 497:True 498:True 499:True 500:True 501:True 502:True 503:True 504:True 505:True 506:True 507:True 508:True 509:True\n",
      "INFO:tensorflow:input_ids: 101 2054 2003 1996 15973 3037 1029 102 1017 1003 3930 1999 6702 2058 1996 10975 28471 2271 2095 1012 2174 1010 2115 2194 1005 1055 6702 3473 2011 1021 1003 4102 2000 2197 2095 1012 2582 1010 1999 1996 4610 2512 1011 21839 6903 1010 2073 2115 2194 3701 5748 1010 2007 7400 1999 1996 3541 3006 1010 2256 3006 3745 2038 3445 2000 4029 1003 2005 1996 3361 2095 2494 1011 5840 4102 2000 2861 1003 2197 2095 1012 16021 23270 2063 1997 7860 4320 2011 1996 3068 1999 3408 1997 2152 2110 2504 7773 1999 2433 1997 9542 1998 1013 2030 4443 4171 1025 20673 11533 15001 4531 2037 2126 2046 1996 4968 3006 1998 2007 1996 7375 1997 1996 1520 15001 1998 2060 9098 3688 1006 13574 1997 15147 1004 7816 1997 3119 1004 6236 1010 2537 1010 4425 1004 4353 1007 2552 1010 2494 1005 4621 2013 1015 1008 2089 1010 2432 1010 2115 2194 2003 2358 3089 6455 2000 3623 2049 4341 6702 1998 3006 3745 1010 2926 1999 2049 4563 6089 1012 11252 7427 1024 1996 11252 7427 2004 4844 2011 1996 2604 2005 3919 1998 3361 8735 1006 12170 19699 1007 6819 3207 2049 2344 6052 2385 1013 2260 1013 2526 2003 2108 7528 2938 11921 16761 6588 1012 1996 2968 2837 2003 8822 1996 5082 1997 1996 5679 1012 3361 2836 2007 4847 2000 6515 2836 1520 1996 4341 6599 1997 2115 2194 2076 1996 2095 2001 2012 12667 1012 24559 21472 1012 2385 18749 2015 2004 2114 2004 1012 1002 26871 2692 1012 6365 18749 2015 1999 1996 3025 2095 1010 4760 1037 6689 1997 1020 1012 4229 1003 1010 2174 1010 1996 5618 2044 4171 2005 1996 2095 3445 2011 2105 5401 1003 2013 27424 1010 28245 1012 2570 18749 2015 1999 1996 3025 2095 2000 2010 1012 25374 1012 5824 18749 2015 2023 2095 1012 1996 9167 6599 7013 2076 1996 2095 2494 1011 5840 2001 27424 1012 22884 2692 1012 6021 18749 2015 1012 2023 2836 2038 2042 4762 3709 6970 4862 2050 1010 2011 2536 3740 2047 5821 11107 7682 5909 1010 2029 2038 4423 1520 2256 7325 2918 4237 2013 1996 7367 26061 2072 3465 7494 5761 10607 2011 2115 2194 1999 2049 3136 1010 2115 2194 4247 2000 2031 1996 2309 2922 4435 1999 1996 7163 15001 6903 1999 1996 2406 1010 11328 5815 2000 2049 3006 3745 1012 1999 3193 1997 1996 14830 6409 1010 2115 5501 2024 4039 2000 16755 1037 11443 4859 1012 4964 12816 1024 2045 2024 2053 4964 12816 2349 2015 14223 24565 3672 2011 1996 2194 1012 3037 2489 5857 2031 2042 2363 2013 9228 2875 1520 26512 1521 6691 1521 1010 2004 2856 2011 1996 12170 19699 6819 3207 2049 2344 6052 2385 1000 2285 1010 2526 10439 22046 1996 11252 5679 1012 1996 2194 2038 4162 2000 1996 2533 1997 2194 3821 2005 11819 2075 2122 28258 2013 8910 1997 2930 1055 2620 2050 1997 1996 3316 2552 1010 3838 1998 2060 12711 3513 1998 8910 102 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n"
     ]
    }
   ],
   "source": [
    "features = convert_examples_to_features(\n",
    "            examples=examples,\n",
    "            label_list=labels,\n",
    "            tokenizer=tokenizer,\n",
    "            max_seq_length=max_seq_length,\n",
    "            doc_stride=doc_stride,\n",
    "            max_query_length=max_query_length,\n",
    "            is_training=False,\n",
    "            pad_token_label_id=pad_token_label_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n",
    "all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n",
    "all_bboxes = torch.tensor([f.boxes for f in features], dtype=torch.long)\n",
    "all_example_index = torch.arange(all_input_ids.size(0), dtype=torch.long)\n",
    "\n",
    "eval_dataset = TensorDataset(\n",
    "        all_input_ids, all_input_mask, all_segment_ids,all_bboxes,all_example_index)\n",
    "eval_batch_size = 1\n",
    "eval_sampler = (\n",
    "        SequentialSampler(eval_dataset))\n",
    "\n",
    "eval_dataloader = DataLoader(\n",
    "        eval_dataset, sampler=eval_sampler, batch_size=eval_batch_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 7/7 [00:01<00:00,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------+-------------------------------------------------------------+\n",
      "| Question                            | Answer                                                      |\n",
      "+=====================================+=============================================================+\n",
      "| what is the title of the document ? | management report of the directors an discussion & analysis |\n",
      "+-------------------------------------+-------------------------------------------------------------+\n",
      "| what is the title of the document ? | [CLS]                                                       |\n",
      "+-------------------------------------+-------------------------------------------------------------+\n",
      "| what is the title of the document ? | [CLS]                                                       |\n",
      "+-------------------------------------+-------------------------------------------------------------+\n",
      "| what is the title of the document ? | [CLS]                                                       |\n",
      "+-------------------------------------+-------------------------------------------------------------+\n",
      "| what is the numerical interest ?    | 4145 / 90                                                   |\n",
      "+-------------------------------------+-------------------------------------------------------------+\n",
      "| what is the numerical interest ?    | [CLS]                                                       |\n",
      "+-------------------------------------+-------------------------------------------------------------+\n",
      "| what is the numerical interest ?    | [CLS]                                                       |\n",
      "+-------------------------------------+-------------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "all_results = []\n",
    "table_data = []\n",
    "\n",
    "def to_list(tensor):\n",
    "    return tensor.detach().cpu().tolist()\n",
    "\n",
    "for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "    model.eval()\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    with torch.no_grad():\n",
    "        inputs = {\n",
    "            \"input_ids\": batch[0],\n",
    "            \"attention_mask\": batch[1],\n",
    "        }\n",
    "        inputs[\"bbox\"] = batch[3]\n",
    "        inputs[\"token_type_ids\"] = (batch[2])\n",
    "        outputs = model(**inputs)\n",
    "    example_indices = batch[4]\n",
    "\n",
    "    for i, example_index in enumerate(example_indices):\n",
    "        eval_feature = features[example_index.item()]\n",
    "        unique_id = int(eval_feature.unique_id)\n",
    "\n",
    "        output = [to_list(output[i]) for output in outputs]\n",
    "\n",
    "        start_logits, end_logits = output\n",
    "        result = SquadResult(unique_id, start_logits, end_logits)\n",
    "        all_results.append(result)\n",
    "predictions_json = {}\n",
    "assert len(all_results)==len(features)\n",
    "for i in range(len(all_results)):\n",
    "    start_index = np.argmax(all_results[i].start_logits)\n",
    "    end_index = np.argmax(all_results[i].end_logits)\n",
    "    pred_answer = features[i].tokens[start_index:end_index+1]\n",
    "    pred_answer = ' '.join([x for x in pred_answer])\n",
    "    pred_text = pred_answer.replace(' ##', '')\n",
    "    question = features[i].tokens[1:features[i].tokens.index('[SEP]')]\n",
    "    question_text = ' '.join([x for x in question])\n",
    "    question_text = question_text.replace(' ##', '')\n",
    "    table_data.append([question_text, pred_text])\n",
    "    # print(question_text)\n",
    "    # print(pred_text) \n",
    "\n",
    "\n",
    "headers = [\"Question\", \"Answer\"]\n",
    "print(tabulate(table_data, headers=headers, tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
